{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM3lbO6hWOSKH0+voDBhaf8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Manav9547/AI-ChatBot/blob/main/Second(SVM).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PZFtFmvR4zuM",
        "outputId": "70990ff4-3863-47d0-cc39-3bae52d865ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading data...\n",
            "Engineering features...\n",
            "Numerical Features: 15\n",
            "Categorical Features: 7\n",
            "\n",
            "Training SVM (Nystroem Approximation)...\n",
            "SVM Validation AUC: 0.75086\n",
            "\n",
            "Training Neural Network...\n",
            "Neural Network Validation AUC: 0.75549\n",
            "Ensemble Validation AUC: 0.75519\n",
            "\n",
            "Retraining on FULL dataset for submission...\n",
            "\n",
            "Prediction Stats:\n",
            "count    51070.000000\n",
            "mean         0.116107\n",
            "std          0.100808\n",
            "min          0.001761\n",
            "25%          0.044481\n",
            "50%          0.083334\n",
            "75%          0.151957\n",
            "max          0.833335\n",
            "Name: RiskFlag, dtype: float64\n",
            "\n",
            "Success! File saved as 'submission_improved.csv'\n"
          ]
        }
      ],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler, RobustScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.kernel_approximation import Nystroem\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 1. Configuration\n",
        "# ------------------------------------------------------------------------------\n",
        "TRAIN_PATH = \"train_updated.csv\"\n",
        "TEST_PATH  = \"test_updated.csv\"\n",
        "SAMPLE_PATH = \"sample_submission_updated.csv\"\n",
        "TARGET = \"RiskFlag\"\n",
        "ID_COL = \"ProfileID\"\n",
        "RANDOM_STATE = 42\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 2. Feature Engineering Function\n",
        "# ------------------------------------------------------------------------------\n",
        "def engineer_features(df):\n",
        "    df = df.copy()\n",
        "\n",
        "    # Avoid division by zero\n",
        "    epsilon = 1e-6\n",
        "\n",
        "    # --- Ratio Features (Critical for Credit Risk) ---\n",
        "\n",
        "    # Loan to Income Ratio (LTI): High LTI -> Higher Risk\n",
        "    df['LTI'] = df['RequestedSum'] / (df['AnnualEarnings'] + epsilon)\n",
        "\n",
        "    # Monthly Income approximation\n",
        "    df['MonthlyIncome'] = df['AnnualEarnings'] / 12.0\n",
        "\n",
        "    # Estimated Monthly EMI (Simplified assumption)\n",
        "    # Total Repayment = Principal + (Principal * Rate * Years / 100)\n",
        "    loan_years = df['RepayPeriod'] / 12.0\n",
        "    total_interest = df['RequestedSum'] * (df['OfferRate'] / 100.0) * loan_years\n",
        "    total_amount = df['RequestedSum'] + total_interest\n",
        "    df['EstimatedEMI'] = total_amount / (df['RepayPeriod'] + epsilon)\n",
        "\n",
        "    # Debt Service Coverage Ratio proxy\n",
        "    df['EMI_to_Income'] = df['EstimatedEMI'] / (df['MonthlyIncome'] + epsilon)\n",
        "\n",
        "    # Trust per Year of Age (Older people with low trust might be riskier)\n",
        "    df['Trust_Per_Year'] = df['TrustMetric'] / (df['ApplicantYears'] + epsilon)\n",
        "\n",
        "    # Disposable Income Proxy\n",
        "    df['DisposableIncome'] = df['MonthlyIncome'] - df['EstimatedEMI']\n",
        "\n",
        "    return df\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 3. Load and Prepare Data\n",
        "# ------------------------------------------------------------------------------\n",
        "print(\"Loading data...\")\n",
        "train = pd.read_csv(TRAIN_PATH)\n",
        "test = pd.read_csv(TEST_PATH)\n",
        "sample = pd.read_csv(SAMPLE_PATH)\n",
        "\n",
        "# Apply Feature Engineering\n",
        "print(\"Engineering features...\")\n",
        "train_eng = engineer_features(train)\n",
        "test_eng = engineer_features(test)\n",
        "\n",
        "X = train_eng.drop(columns=[TARGET, ID_COL])\n",
        "y = train_eng[TARGET]\n",
        "X_test = test_eng.drop(columns=[ID_COL])\n",
        "\n",
        "# Identify columns\n",
        "num_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
        "cat_cols = X.select_dtypes(include=['object']).columns.tolist()\n",
        "\n",
        "print(f\"Numerical Features: {len(num_cols)}\")\n",
        "print(f\"Categorical Features: {len(cat_cols)}\")\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 4. Preprocessing Pipeline\n",
        "# ------------------------------------------------------------------------------\n",
        "# RobustScaler handles outliers better than StandardScaler for income/loans\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='median')),\n",
        "    ('scaler', RobustScaler())\n",
        "])\n",
        "\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
        "])\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_transformer, num_cols),\n",
        "        ('cat', categorical_transformer, cat_cols)\n",
        "    ]\n",
        ")\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 5. Model Definitions\n",
        "# ------------------------------------------------------------------------------\n",
        "\n",
        "# --- Model A: Non-Linear SVM (Approximated) ---\n",
        "# Standard SVC is O(N^3). For 200k rows, we use Nystroem + LinearSVC (O(N))\n",
        "# to approximate the RBF kernel map efficiently.\n",
        "svm_pipeline = Pipeline([\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('nystroem', Nystroem(kernel='rbf', gamma=0.1, n_components=400, random_state=RANDOM_STATE)),\n",
        "    ('clf', CalibratedClassifierCV(\n",
        "        estimator=LinearSVC(dual=False, C=1.0, class_weight='balanced', max_iter=2000, random_state=RANDOM_STATE),\n",
        "        method='isotonic',\n",
        "        cv=3\n",
        "    ))\n",
        "])\n",
        "\n",
        "# --- Model B: Deep Neural Network ---\n",
        "# Deeper architecture (256->128->64) to capture complex patterns\n",
        "nn_pipeline = Pipeline([\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('clf', MLPClassifier(\n",
        "        hidden_layer_sizes=(256, 128, 64),\n",
        "        activation='relu',\n",
        "        solver='adam',\n",
        "        alpha=0.0001,\n",
        "        batch_size=256,\n",
        "        learning_rate_init=0.001,\n",
        "        max_iter=200,\n",
        "        early_stopping=True,\n",
        "        validation_fraction=0.1,\n",
        "        random_state=RANDOM_STATE\n",
        "    ))\n",
        "])\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 6. Training and Validation\n",
        "# ------------------------------------------------------------------------------\n",
        "# We use a holdout set for local validation to estimate Kaggle score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train_sub, X_val_sub, y_train_sub, y_val_sub = train_test_split(\n",
        "    X, y, test_size=0.2, stratify=y, random_state=RANDOM_STATE\n",
        ")\n",
        "\n",
        "print(\"\\nTraining SVM (Nystroem Approximation)...\")\n",
        "svm_pipeline.fit(X_train_sub, y_train_sub)\n",
        "svm_preds_val = svm_pipeline.predict_proba(X_val_sub)[:, 1]\n",
        "svm_auc = roc_auc_score(y_val_sub, svm_preds_val)\n",
        "print(f\"SVM Validation AUC: {svm_auc:.5f}\")\n",
        "\n",
        "print(\"\\nTraining Neural Network...\")\n",
        "nn_pipeline.fit(X_train_sub, y_train_sub)\n",
        "nn_preds_val = nn_pipeline.predict_proba(X_val_sub)[:, 1]\n",
        "nn_auc = roc_auc_score(y_val_sub, nn_preds_val)\n",
        "print(f\"Neural Network Validation AUC: {nn_auc:.5f}\")\n",
        "\n",
        "# Ensemble (Average)\n",
        "ensemble_preds_val = (svm_preds_val + nn_preds_val) / 2\n",
        "ensemble_auc = roc_auc_score(y_val_sub, ensemble_preds_val)\n",
        "print(f\"Ensemble Validation AUC: {ensemble_auc:.5f}\")\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 7. Final Training on Full Data & Submission\n",
        "# ------------------------------------------------------------------------------\n",
        "print(\"\\nRetraining on FULL dataset for submission...\")\n",
        "\n",
        "# Train SVM on full data\n",
        "svm_pipeline.fit(X, y)\n",
        "test_probs_svm = svm_pipeline.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Train NN on full data\n",
        "nn_pipeline.fit(X, y)\n",
        "test_probs_nn = nn_pipeline.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Ensemble\n",
        "test_probs_ens = (test_probs_svm * 0.5) + (test_probs_nn * 0.5)\n",
        "\n",
        "# Create Submission DataFrame\n",
        "submission = pd.DataFrame({\n",
        "    ID_COL: test[ID_COL],\n",
        "    TARGET: test_probs_ens\n",
        "})\n",
        "\n",
        "# Ensure strict sorting alignment with sample submission if needed\n",
        "# (Kaggle usually evaluates based on ID match, but sorting is safer)\n",
        "sample_ids = sample[ID_COL].values\n",
        "submission = submission.set_index(ID_COL).reindex(sample_ids).reset_index()\n",
        "\n",
        "# Check distribution\n",
        "print(\"\\nPrediction Stats:\")\n",
        "print(submission[TARGET].describe())\n",
        "\n",
        "# Save\n",
        "submission.to_csv(\"submission_improved.csv\", index=False)\n",
        "print(\"\\nSuccess! File saved as 'submission_improved.csv'\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "IN = \"submission_improved.csv\"  # or your model output\n",
        "OUT = \"submission_binary_improved.csv\"\n",
        "\n",
        "df = pd.read_csv(IN)\n",
        "predcol = df.columns[1]\n",
        "\n",
        "# ensure numeric\n",
        "df[predcol] = pd.to_numeric(df[predcol], errors=\"coerce\").fillna(0.5)\n",
        "\n",
        "# choose threshold (0.5 default). You can tune threshold on validation set.\n",
        "threshold = 0.5\n",
        "df[predcol] = (df[predcol] >= threshold).astype(int)\n",
        "\n",
        "df.to_csv(OUT, index=False)\n",
        "print(\"Saved binary submission to:\", OUT)\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mhwwMaYSPkCR",
        "outputId": "d969dd4e-d2c6-4e6c-88c2-bb27cf383759"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved binary submission to: submission_binary_improved.csv\n",
            "    ProfileID  RiskFlag\n",
            "0  CKV34LU7V7         0\n",
            "1  62KTYNH93J         0\n",
            "2  JGFUSOIUH7         0\n",
            "3  4538THBHOX         0\n",
            "4  DXLNA06JHR         0\n"
          ]
        }
      ]
    }
  ]
}